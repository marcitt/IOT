{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general imports\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "from IPython.display import display, Image\n",
    "import ipywidgets as widgets\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ml imports \n",
    "import torch\n",
    "import torchvision\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_v5_model(model): \n",
    "    # Stop button\n",
    "    # ================\n",
    "    stopButton = widgets.ToggleButton(\n",
    "        value=False,\n",
    "        description=\"Stop\",\n",
    "        disabled=False,\n",
    "        button_style=\"danger\",  # 'success', 'info', 'warning', 'danger' or ''\n",
    "        tooltip=\"Description\",\n",
    "        icon=\"square\",  # (FontAwesome names without the `fa-` prefix)\n",
    "    )\n",
    "\n",
    "    # Display function\n",
    "    # ================\n",
    "    def view(button):\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        display_handle = display(None, display_id=True)\n",
    "        i = 0\n",
    "        while True:\n",
    "            _, frame = cap.read()\n",
    "            frame = cv2.flip(frame, 1)  # if your camera reverses your image\n",
    "\n",
    "            results = model(frame)\n",
    "            frame = np.squeeze(results.render()[0])\n",
    "\n",
    "            _, frame = cv2.imencode(\".jpeg\", frame)\n",
    "            display_handle.update(Image(data=frame.tobytes()))\n",
    "            if stopButton.value == True:\n",
    "                cap.release()\n",
    "                display_handle.update(None)\n",
    "\n",
    "    # Run\n",
    "    # ================\n",
    "    display(stopButton)\n",
    "    thread = threading.Thread(target=view, args=(stopButton,))\n",
    "    thread.start()\n",
    "\n",
    "# Reference: https://abauville.medium.com/display-your-live-webcam-feed-in-a-jupyter-notebook-using-opencv-d01eb75921d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test version 1 of the model trained on 75 focused images & 75 unfocused images\n",
    "\n",
    "attention_model_v1 = torch.hub.load(\n",
    "    \"ultralytics/yolov5\",\n",
    "    \"custom\",\n",
    "    path=\"model_iterations/v1/weights/best.pt\",\n",
    "    force_reload=True,\n",
    ")\n",
    "\n",
    "run_v5_model(attention_model_v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_v8_model(model): \n",
    "    threshold = 0.5\n",
    "\n",
    "    # Stop button\n",
    "    # ================\n",
    "    stopButton = widgets.ToggleButton(\n",
    "        value=False,\n",
    "        description=\"Stop\",\n",
    "        disabled=False,\n",
    "        button_style=\"danger\",  # 'success', 'info', 'warning', 'danger' or ''\n",
    "        tooltip=\"Description\",\n",
    "        icon=\"square\",  # (FontAwesome names without the `fa-` prefix)\n",
    "    )\n",
    "\n",
    "\n",
    "    # Display function\n",
    "    # ================\n",
    "    def view(button):\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        display_handle = display(None, display_id=True)\n",
    "        i = 0\n",
    "        while True:\n",
    "            _, frame = cap.read()\n",
    "            frame = cv2.flip(frame, 1)  # if your camera reverses your image\n",
    "\n",
    "            results = model(frame)[0]\n",
    "\n",
    "            for result in results.boxes.data.tolist():\n",
    "                x1, y1, x2, y2, score, class_id = result\n",
    "\n",
    "                if class_id == 16:\n",
    "                    colour = (20, 200, 0)\n",
    "                    # 16 = focused\n",
    "                elif class_id == 15:\n",
    "                    colour = (0, 0, 255)\n",
    "                    # 15 = distracted\n",
    "                else:\n",
    "                    colour = (255, 255, 0)\n",
    "\n",
    "                if score > threshold:\n",
    "                    cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), colour, 4)\n",
    "                    cv2.putText(\n",
    "                        frame,\n",
    "                        f\"{class_id}{results.names[int(class_id)].upper()} {round(score, 4)}\",\n",
    "                        (int(x1), int(y1 - 10)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        1.3,\n",
    "                        colour,\n",
    "                        3,\n",
    "                        cv2.LINE_AA,\n",
    "                    )\n",
    "\n",
    "            _, frame = cv2.imencode(\".jpeg\", frame)\n",
    "            display_handle.update(Image(data=frame.tobytes()))\n",
    "            if stopButton.value == True:\n",
    "                cap.release()\n",
    "                display_handle.update(None)\n",
    "\n",
    "\n",
    "    # Run\n",
    "    # ================\n",
    "    display(stopButton)\n",
    "    thread = threading.Thread(target=view, args=(stopButton,))\n",
    "    thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing run v8 model code\n",
    "attention_model_v4 = YOLO(\"model_iterations/v4/weights/best.pt\")\n",
    "run_v8_model(attention_model_v4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iot_opencv_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
